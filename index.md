## Organizers
<p style="text-align: center;"> Sean Fanello, Christoph Rhemann, Graham Fyffe,  Jonathan Taylor, Sofien Bouaziz, Paul Debevec, Shahram Izadi
</p>
<p style="text-align: center;"> <b> Google </b> </p>

## Description
Volumetric (4D) performance capture is fundamental for AR/VR content generation.  Designing a volumetric capture pipeline involves developing a full computer vision stack: from novel sensors to efficient volumetric reconstruction algorithms, compression and rendering. To this end, we leverage a combination of active sensors with traditional photometric stereo methods. As a result, we have developed an unique pipeline for reconstruction, tracking and texturing of humans in 4D.

In this tutorial we will walk the attendee through the ins and outs of building such a system from the ground up.

First, we will consider the hardware design choices for cameras, sensors, lighting, and depth estimation algorithms. 

In the second part we will cover reconstruction and tracking techniques for people. We will review state of the art algorithms to generate high quality meshes and volumetric representations.

In the third part we will focus on photometric stereo, texturing, relightability and rendering: we will detail the state of the art algorithms together with our choices.

Finally we will discuss some applications and capabilities that 3D capture technologies enable. We will put emphasis on virtual and augmented reality scenarios and highlight recent trends in machine learning that aim at replacing traditional graphics pipelines.

## When and Where
June 16th -  Long Beach Convention Center in Long Beach, Room 201A

## Program
Coming soon

Please contact [Shahram Izadi](mailto:shahrami@google.com) or [Sean Fanello](mailto:seanfa@google.com) if you have any questions.
