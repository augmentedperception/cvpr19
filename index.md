## Organizers
<p style="text-align: center;"> Sean Fanello, Christoph Rhemann, Graham Fyffe,  Jonathan Taylor, Sofien Bouaziz, Paul Debevec, Shahram Izadi
</p>
<p style="text-align: center;"> <b> Google </b> </p>

## Description
Volumetric (4D) performance capture is fundamental for AR/VR content generation.  Designing a volumetric capture pipeline involves developing high quality sensors and efficient algorithms that can leverage new and existing sensing technology. To this end, we leverage a combination of active sensors with traditional photometric stereo methods. As a result, we have developed a wide range of high quality algorithms for reconstruction, tracking and texturing of humans in 4D.

In this tutorial we will walk the attendee through the ins and outs of building such a system from the ground up.

In the first part of this we will consider the hardware design choices for cameras, sensors, lighting, and depth estimation algorithms.  We then walk through the proposed RGBD active sensors to achieve high quality results with reasonable runtime.

In the second part we will cover reconstruction and tracking techniques for people. We will review state of the art algorithms such as Kinect Fusion, Dynamic Fusion, Fusion4D and Motion2Fusion. We will also detail parametric tracking approaches for faces, hands and bodies. 

In the third part we will focus on photometric stereo, texturing and relightability: we will detail the state of the art algorithm together with our choices.

Finally we will discuss some applications and capabilities that 3D capture technologies enable. We will put emphasis on virtual and augmented reality scenarios and highlight recent trends in machine learning that aim at replacing traditional graphics pipelines.

## When and Where
Coming soon

## Program
Coming soon

Please contact  [Shahram Izadi](mailto:shahrami@google.com) or [Sean Fanello](mailto:seanfa@google.com) if you have any questions.
